<div align="right">

![Version](https://img.shields.io/badge/Version-0.0.1-blue?style=flat) 
![License](https://img.shields.io/badge/License-MIT-blue?style=flat) 
![Python](https://img.shields.io/badge/Language-Python-blue?style=flat) 

</div>

# An√°lisis de Tweets - Desaf√≠o Ingenier√≠a de Datos LATAM Airlines

Soluci√≥n al desaf√≠o de procesamiento eficiente de ~398MB de datos de Twitter (farmers-protest-tweets-2021-2-4.json), implementando optimizaciones de memoria y tiempo con Python y Google Cloud Platform.

## üìã Resumen del Desaf√≠o

El dataset contiene tweets relacionados con las protestas de agricultores en India (2021), con m√°s de 400K registros. El desaf√≠o consiste en procesar eficientemente este volumen de datos para extraer insights clave, priorizando ya sea velocidad de ejecuci√≥n o uso m√≠nimo de memoria RAM.

## üéØ Descripci√≥n del Proyecto

El proyecto resuelve tres problemas de an√°lisis de datos (questions/preguntas):

1. **Q1**: Top 10 fechas con m√°s tweets, identificando el usuario m√°s activo por d√≠a
2. **Q2**: Top 10 emojis m√°s utilizados con sus conteos
3. **Q3**: Top 10 usuarios m√°s mencionados en tweets

Cada problema (`qX_*.py` donde X es el n√∫mero de pregunta) tiene dos implementaciones:
- **time**: Optimizada para tiempo de ejecuci√≥n usando pandas
- **memory**: Optimizada para consumo de memoria procesamiento l√≠nea a l√≠nea.

**Contexto del Dataset:** El archivo JSON contiene ~400K tweets relacionados con las protestas de agricultores en India durante 2021, recopilados de Twitter.

## ‚öôÔ∏è Arquitectura

El proyecto incluye:
- Procesamiento de datos con Python y Pandas
- Infraestructura en GCP (Storage, BigQuery, Cloud Run)
- CI/CD automatizado con GitHub Actions  
- Infraestructura como c√≥digo con Terraform
- An√°lisis de rendimiento con memory-profiler
- Pre-commit hooks (Ruff para linting/formato, Bandit para seguridad)

## üìÅ Estructura del Proyecto

```
.
‚îú‚îÄ‚îÄ Dockerfile                      # Dockerizaci√≥n del proyecto
‚îú‚îÄ‚îÄ LICENSE                         # Licencia del proyecto
‚îú‚îÄ‚îÄ README.md                       # Documentaci√≥n principal
‚îú‚îÄ‚îÄ exploration/                    # Scripts para exploraci√≥n inicial de datos
‚îÇ   ‚îú‚îÄ‚îÄ explore_tweets_q1.py
‚îÇ   ‚îú‚îÄ‚îÄ explore_tweets_q2.py
‚îÇ   ‚îî‚îÄ‚îÄ explore_tweets_q3.py
‚îú‚îÄ‚îÄ notebooks/                      # Cuaderno Jupyter con an√°lisis detallado
‚îÇ   ‚îî‚îÄ‚îÄ challenge_analysis.ipynb
‚îú‚îÄ‚îÄ poetry.lock                     # Archivo lock generado por Poetry
‚îú‚îÄ‚îÄ pyproject.toml                  # Configuraci√≥n del proyecto con Poetry
‚îú‚îÄ‚îÄ requirements.txt                # Dependencias del proyecto para pip
‚îú‚îÄ‚îÄ src/                            # C√≥digo fuente
‚îÇ   ‚îú‚îÄ‚îÄ config.json                 # Configuraci√≥n GCP y dataset
‚îÇ   ‚îú‚îÄ‚îÄ main.py                     # CLI principal con argparse
‚îÇ   ‚îú‚îÄ‚îÄ q1_memory.py                # Problema 1 optimizado para memoria
‚îÇ   ‚îú‚îÄ‚îÄ q1_time.py                  # Problema 1 optimizado para tiempo
‚îÇ   ‚îú‚îÄ‚îÄ q2_memory.py                # Problema 2 optimizado para memoria
‚îÇ   ‚îú‚îÄ‚îÄ q2_time.py                  # Problema 2 optimizado para tiempo
‚îÇ   ‚îú‚îÄ‚îÄ q3_memory.py                # Problema 3 optimizado para memoria
‚îÇ   ‚îú‚îÄ‚îÄ q3_time.py                  # Problema 3 optimizado para tiempo
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                    # Utilidades comunes (GCS, BigQuery, configuraci√≥n)
‚îî‚îÄ‚îÄ terraform/                      # Infraestructura como C√≥digo (IaC)
    ‚îú‚îÄ‚îÄ Makefile                    # Automatizaci√≥n de tareas
    ‚îú‚îÄ‚îÄ backend.tf                  # Configuraci√≥n del backend de Terraform
    ‚îú‚îÄ‚îÄ main.tf                     # Recursos principales en Terraform
    ‚îú‚îÄ‚îÄ modules/                    # M√≥dulos reutilizables
    ‚îÇ   ‚îú‚îÄ‚îÄ bigquery/               # Configuraci√≥n de BigQuery
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset/            # Creaci√≥n de dataset
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tables/             # Creaci√≥n de tablas
    ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ tables_schemas/ # Esquemas JSON para tablas
    ‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ q1_results.json
    ‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ q2_results.json
    ‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ q3_results.json
    ‚îÇ   ‚îú‚îÄ‚îÄ bucket/                 # Configuraci√≥n de Cloud Storage
    ‚îÇ   ‚îî‚îÄ‚îÄ serviceAccount/         # Configuraci√≥n de cuenta de servicio
    ‚îú‚îÄ‚îÄ outputs.tf                  # Outputs definidos en Terraform
    ‚îú‚îÄ‚îÄ variables.tf                # Variables configurables en Terraform
    ‚îú‚îÄ‚îÄ terraform.tfvars.example    # Ejemplo de archivo de variables
    ‚îî‚îÄ‚îÄ versions.tf                 # Versionado de providers
```

## üöÄ Instalaci√≥n y Configuraci√≥n

### Prerrequisitos

- Cuenta de Google Cloud Platform con permisos de administrador
- Terraform >= 1.0
- Google Cloud SDK (gcloud)
- Python 3.12+ con Poetry
- Docker (opcional)

### Setup de Infraestructura

#### 1. Configuraci√≥n inicial del proyecto GCP:

Navega a la carpeta  `terraform/`, edita las variables del archivo Makefile seg√∫n tu configuraci√≥n:
```bash
# Variables de Makefile
PROJECT_ID      ?= <PROJECT_ID>
REGION          ?= <REGION>
TF_BUCKET_NAME  ?= $(PROJECT_ID)-terraform-state
SA_NAME         ?= sa-terraform
SA_EMAIL        = $(SA_NAME)@$(PROJECT_ID).iam.gserviceaccount.com
SA_KEY_FILE     ?= sa/sa-terraform.json
```
 y luego ejecuta los siguientes comandos:
```
# Configurar proyecto
make set-project PROJECT_ID=<YOUR_PROJECT_ID>

# Autenticarse en GCP
make auth-login

# Habilitar APIs necesarias
make enable-apis

# Crear cuenta de servicio para Terraform
make create-sa

# Asignar roles necesarios
make add-sa-roles

# Generar clave de cuenta de servicio (NO commitear)
make create-sa-key

# Crear bucket para estado de Terraform
make create-tf-bucket
```

#### 2. Configurar variables de Terraform:

```bash
# Copiar archivo de ejemplo
cp terraform.tfvars.example terraform.tfvars

# Editar terraform.tfvars con tus valores:
project_id        = "<YOUR_PROJECT_ID>"
repository_id     = "<YOUR_REPOSITORY_ID>"
environment       = "<dev|staging|prod>"
region            = "<YOUR_REGION>"
zone              = "<YOUR_ZONE>"
credentials_file  = "sa/sa-terraform.json"
```

#### 3. Desplegar infraestructura con Terraform:

```bash
# Inicializar Terraform
terraform init

# Revisar plan de ejecuci√≥n
terraform plan

# Aplicar cambios
terraform apply
```

### Configuraci√≥n CI/CD

En GitHub Repository Settings agregar:

**Secrets:**
- `SA_TERRAFORM_KEY`: JSON de cuenta de servicio Terraform
- `SA_DEPLOYMENT_KEY`: JSON de cuenta de servicio deployment

**Variables:**
- `PROJECT_ID`: `<YOUR_PROJECT_ID>`
- `REGION`: `<YOUR_REGION>`
- `ZONE`: `<YOUR_ZONE>`
- `ARTIFACT_REPO`: `<YOUR_ARTIFACT_REPO_NAME>`
- `IMAGE_NAME`: `<YOUR_IMAGE_NAME>`
- `CLOUD_RUN_JOB_NAME`: `<YOUR_JOB_NAME>`
- `ENVIRONMENT`: `<dev|staging|prod>`
- `REPOSITORY_ID`: `<YOUR_REPOSITORY_ID>`

## üíª Uso del Sistema

### Ejecuci√≥n Local

```bash
poetry install
export GOOGLE_APPLICATION_CREDENTIALS="<PATH_TO_SERVICE_ACCOUNT_KEY>.json"

# Ejecutar an√°lisis espec√≠fico
poetry run python src/main.py --question q1 --method time

# Ejecutar todo y guardar en BigQuery
poetry run python src/main.py --question all --method memory --save_bq

# Personalizar top N resultados
poetry run python src/main.py --question q2 --method time --top_n 5
```

### Ejecuci√≥n en Cloud Run

```bash
# Ejecutar job con configuraci√≥n por defecto
gcloud run jobs execute <YOUR_CLOUD_RUN_JOB_NAME> \
  --project=<YOUR_PROJECT_ID> \
  --region=<YOUR_REGION> \
  --wait

# Ejecutar an√°lisis espec√≠fico
gcloud run jobs execute <YOUR_CLOUD_RUN_JOB_NAME> \
  --project=<YOUR_PROJECT_ID> \
  --region=<YOUR_REGION> \
  --args="src/main.py,--question,q1,--method,memory,--save_bq" \
  --wait
```

### Docker Local

```bash
docker build -t <YOUR_IMAGE_NAME> .
docker run --rm \
  -v <PATH_TO_SERVICE_ACCOUNT_KEY>.json:/app/sa.json \
  -e GOOGLE_APPLICATION_CREDENTIALS=/app/sa.json \
  <YOUR_IMAGE_NAME> \
  python src/main.py --question all --method time
```

## üìä Par√°metros CLI (Interfaz de l√≠nea de comandos)

| Par√°metro | Valores posibles | Default | Descripci√≥n |
|-----------|------------------|---------|-------------|
| `--question` | q1, q2, q3, all | all | Qu√© an√°lisis ejecutar |
| `--method` | time, memory | time | Optimizaci√≥n por tiempo o memoria |
| `--top_n` | entero positivo | 10 | N√∫mero de resultados a retornar |
| `--save_bq` | (flag) | false | Guardar resultados en BigQuery |

## üìà Rendimiento y Resultados

Basado en el an√°lisis del notebook con 398MB de tweets:

### Q1 - Top fechas con m√°s tweets
- **M√©todo time**: ~5 segundos, ~207 MiB RAM
- **M√©todo memory**: ~4.5 segundos, ~205 MiB RAM
- **Conclusi√≥n**: Rendimiento similar, ambos m√©todos son eficientes

### Q2 - Top emojis m√°s usados  
- **M√©todo time**: ~5.65 segundos, ~211 MiB RAM
- **M√©todo memory**: ~70 segundos, ~210 MiB RAM
- **Conclusi√≥n**: El m√©todo optimizado para tiempo es ~12x m√°s r√°pido sin penalizar el uso de memoria

### Q3 - Usuarios m√°s mencionados
- **M√©todo time**: ~5.49 segundos, ~210 MiB RAM
- **M√©todo memory**: ~4.58 segundos, ~210 MiB RAM
- **Conclusi√≥n**: Rendimiento pr√°cticamente id√©ntico

### Formato de Resultados

**Q1**: Lista de tuplas (fecha, usuario)
```python
[(datetime.date(2021, 2, 12), "narendramodi"), ...]
```

**Q2**: Lista de tuplas (emoji, conteo)
```python
[("üôè", 5049), ("üòÇ", 3072), ...]
```

**Q3**: Lista de tuplas (usuario, menciones)
```python
[("narendramodi", 2265), ...]
```

## ‚òÅÔ∏è Recursos GCP Creados

**Buckets:**
- `<YOUR_PROJECT_ID>-terraform-state`: Estado de Terraform
- `<YOUR_DATA_BUCKET_NAME>`: Almacenamiento de datos

**BigQuery:**
- Dataset: `<YOUR_BIGQUERY_DATASET>`
- Tablas: `q1_results`, `q2_results`, `q3_results`

**Service Accounts:**
- `sa-terraform`: Gesti√≥n de infraestructura
- `sa-deployment`: Ejecuci√≥n de aplicaci√≥n

**Cloud Run:**
- Job con 2 CPU, 4Gi memoria
- Timeout: 1 hora
- Environment: gen2

## üîÑ Pipeline CI/CD

El pipeline se activa con push a main o develop:

1. **Terraform**: Planifica y aplica cambios de infraestructura
2. **Docker**: Construye imagen y la sube a Artifact Registry
3. **Deploy**: Actualiza Cloud Run Job
4. **Ejecuta**: Corre an√°lisis autom√°ticamente

## üßπ Limpieza

Para eliminar archivos sensibles locales:
```bash
cd terraform && make clean
```

Para destruir infraestructura:
```bash
cd terraform && terraform destroy
```

## ‚öôÔ∏è Archivos de Configuraci√≥n

**config.json** - Configuraci√≥n del proyecto:
```json
{
  "BUCKET": "<YOUR_DATA_BUCKET_NAME>",
  "DATASET_ID": "<YOUR_BIGQUERY_DATASET>", 
  "FILENAME": "farmers-protest-tweets-2021-2-4.json",
  "PROJECT_ID": "<YOUR_PROJECT_ID>"
}
```

**pyproject.toml** - Dependencias principales:
- `pandas`: Procesamiento de datos
- `google-cloud-bigquery`: Integraci√≥n con BigQuery
- `google-cloud-storage`: Manejo de archivos en GCS
- `memory-profiler`: An√°lisis de consumo de memoria

## üìì Notebooks y An√°lisis

`notebooks/challenge_analysis.ipynb` contiene:
- Exploraci√≥n inicial del dataset
- Comparaci√≥n detallada entre m√©todos time y memory
- An√°lisis de rendimiento con memory-profiler
- Visualizaci√≥n de resultados
- Conclusiones y recomendaciones

## üìÑ Licencia

Este proyecto est√° bajo la licencia MIT. Ver el archivo [LICENSE](LICENSE) para m√°s detalles.

## ü§ù Contribuciones

Las contribuciones son bienvenidas. Por favor:
1. Fork el proyecto
2. Crea tu feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push al branch (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---
